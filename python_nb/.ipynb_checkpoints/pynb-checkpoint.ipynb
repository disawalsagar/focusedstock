{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import FundamentalAnalysis as fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#read csv\n",
    "pd1 = pd.read_csv('/dbfs/FileStore/tables/rbh.csv')\n",
    "#\n",
    "api_key = \"9b3eb12c236953d7647d9a758a1a1637\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">&lt;class &#39;str&#39;&gt;\n",
       "&lt;class &#39;str&#39;&gt;\n",
       "&lt;class &#39;str&#39;&gt;\n",
       "&lt;class &#39;str&#39;&gt;\n",
       "&lt;class &#39;str&#39;&gt;\n",
       "&lt;class &#39;str&#39;&gt;\n",
       "&lt;class &#39;str&#39;&gt;\n",
       "&lt;class &#39;str&#39;&gt;\n",
       "&lt;class &#39;str&#39;&gt;\n",
       "&lt;class &#39;str&#39;&gt;\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# iterate over all the elements \n",
    "pd2 = pd1['Symbol']\n",
    "for counter, items in pd2.iteritems(): \n",
    "\tticker = \"AAPL\"\n",
    "    print(items) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sx = fa.quote(\"AAPL\",api_key)\n",
    "#balance_sheet_annually = fa.balance_sheet_statement(ticker, api_key, period=\"annual\")\n",
    "#balance_sheet_annually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-3054368902533677&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>display<span class=\"ansi-blue-fg\">(</span>sx<span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/local_disk0/tmp/1599998959116-0/PythonShell.py</span> in <span class=\"ansi-cyan-fg\">display</span><span class=\"ansi-blue-fg\">(self, input, *args, **kwargs)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1095</span>             <span class=\"ansi-green-fg\">if</span> self<span class=\"ansi-blue-fg\">.</span>sparkSession <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1096</span>                 <span class=\"ansi-green-fg\">raise</span> Exception<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;SparkSession is required for display(pandas.DataFrame).&#39;</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1097</span><span class=\"ansi-red-fg\">             </span>self<span class=\"ansi-blue-fg\">.</span>display<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>sparkSession<span class=\"ansi-blue-fg\">.</span>createDataFrame<span class=\"ansi-blue-fg\">(</span>input<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1098</span>         <span class=\"ansi-green-fg\">elif</span> type<span class=\"ansi-blue-fg\">(</span>input<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>__module__ <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-blue-fg\">&#39;databricks.koalas.frame&#39;</span> <span class=\"ansi-green-fg\">and</span> type<span class=\"ansi-blue-fg\">(</span>input<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>__name__ <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-blue-fg\">&#39;DataFrame&#39;</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1099</span>             index_col <span class=\"ansi-blue-fg\">=</span> kwargs<span class=\"ansi-blue-fg\">.</span>get<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;index_col&#39;</span><span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">createDataFrame</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    650</span>             <span class=\"ansi-red-fg\"># Create a DataFrame from pandas DataFrame.</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    651</span>             return super(SparkSession, self).createDataFrame(\n",
       "<span class=\"ansi-green-fg\">--&gt; 652</span><span class=\"ansi-red-fg\">                 data, schema, samplingRatio, verifySchema)\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">    653</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_create_dataframe<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    654</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/pandas/conversion.py</span> in <span class=\"ansi-cyan-fg\">createDataFrame</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    300</span>                     <span class=\"ansi-green-fg\">raise</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    301</span>         data <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_convert_from_pandas<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> timezone<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 302</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_create_dataframe<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    303</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    304</span>     <span class=\"ansi-green-fg\">def</span> _convert_from_pandas<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> pdf<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> timezone<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_create_dataframe</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    683</span>                 rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromRDD<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    684</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 685</span><span class=\"ansi-red-fg\">                 </span>rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromLocal<span class=\"ansi-blue-fg\">(</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    686</span>             jrdd <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>SerDeUtil<span class=\"ansi-blue-fg\">.</span>toJavaArray<span class=\"ansi-blue-fg\">(</span>rdd<span class=\"ansi-blue-fg\">.</span>_to_java_object_rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    687</span>             jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>applySchemaToPythonRDD<span class=\"ansi-blue-fg\">(</span>jrdd<span class=\"ansi-blue-fg\">.</span>rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">.</span>json<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_createFromLocal</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    468</span>         write temp files<span class=\"ansi-blue-fg\">.</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    469</span>         &#34;&#34;&#34;\n",
       "<span class=\"ansi-green-fg\">--&gt; 470</span><span class=\"ansi-red-fg\">         </span>data<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_wrap_data_schema<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    471</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">.</span>parallelize<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    472</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_wrap_data_schema</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    447</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    448</span>         <span class=\"ansi-green-fg\">if</span> schema <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span> <span class=\"ansi-green-fg\">or</span> isinstance<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>list<span class=\"ansi-blue-fg\">,</span> tuple<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 449</span><span class=\"ansi-red-fg\">             </span>struct <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_inferSchemaFromList<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> names<span class=\"ansi-blue-fg\">=</span>schema<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    450</span>             converter <span class=\"ansi-blue-fg\">=</span> _create_converter<span class=\"ansi-blue-fg\">(</span>struct<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    451</span>             data <span class=\"ansi-blue-fg\">=</span> map<span class=\"ansi-blue-fg\">(</span>converter<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_inferSchemaFromList</span><span class=\"ansi-blue-fg\">(self, data, names)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    383</span>             warnings.warn(&#34;inferring schema from dict is deprecated,&#34;\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    384</span>                           &#34;please use pyspark.sql.Row instead&#34;)\n",
       "<span class=\"ansi-green-fg\">--&gt; 385</span><span class=\"ansi-red-fg\">         </span>schema <span class=\"ansi-blue-fg\">=</span> reduce<span class=\"ansi-blue-fg\">(</span>_merge_type<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>_infer_schema<span class=\"ansi-blue-fg\">(</span>row<span class=\"ansi-blue-fg\">,</span> names<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> row <span class=\"ansi-green-fg\">in</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    386</span>         <span class=\"ansi-green-fg\">if</span> _has_nulltype<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    387</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Some of types cannot be determined after inferring&#34;</span><span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/types.py</span> in <span class=\"ansi-cyan-fg\">_merge_type</span><span class=\"ansi-blue-fg\">(a, b, name)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1104</span>         fields = [StructField(f.name, _merge_type(f.dataType, nfs.get(f.name, NullType()),\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1105</span>                                                   name=new_name(f.name)))\n",
       "<span class=\"ansi-green-fg\">-&gt; 1106</span><span class=\"ansi-red-fg\">                   for f in a.fields]\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1107</span>         names <span class=\"ansi-blue-fg\">=</span> set<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span>f<span class=\"ansi-blue-fg\">.</span>name <span class=\"ansi-green-fg\">for</span> f <span class=\"ansi-green-fg\">in</span> fields<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1108</span>         <span class=\"ansi-green-fg\">for</span> n <span class=\"ansi-green-fg\">in</span> nfs<span class=\"ansi-blue-fg\">:</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/types.py</span> in <span class=\"ansi-cyan-fg\">&lt;listcomp&gt;</span><span class=\"ansi-blue-fg\">(.0)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1104</span>         fields = [StructField(f.name, _merge_type(f.dataType, nfs.get(f.name, NullType()),\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1105</span>                                                   name=new_name(f.name)))\n",
       "<span class=\"ansi-green-fg\">-&gt; 1106</span><span class=\"ansi-red-fg\">                   for f in a.fields]\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1107</span>         names <span class=\"ansi-blue-fg\">=</span> set<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span>f<span class=\"ansi-blue-fg\">.</span>name <span class=\"ansi-green-fg\">for</span> f <span class=\"ansi-green-fg\">in</span> fields<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1108</span>         <span class=\"ansi-green-fg\">for</span> n <span class=\"ansi-green-fg\">in</span> nfs<span class=\"ansi-blue-fg\">:</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/types.py</span> in <span class=\"ansi-cyan-fg\">_merge_type</span><span class=\"ansi-blue-fg\">(a, b, name)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1097</span>     <span class=\"ansi-green-fg\">elif</span> type<span class=\"ansi-blue-fg\">(</span>a<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> type<span class=\"ansi-blue-fg\">(</span>b<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1098</span>         <span class=\"ansi-red-fg\"># TODO: type cast (such as int -&gt; long)</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1099</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">raise</span> TypeError<span class=\"ansi-blue-fg\">(</span>new_msg<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Can not merge type %s and %s&#34;</span> <span class=\"ansi-blue-fg\">%</span> <span class=\"ansi-blue-fg\">(</span>type<span class=\"ansi-blue-fg\">(</span>a<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> type<span class=\"ansi-blue-fg\">(</span>b<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1100</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1101</span>     <span class=\"ansi-red-fg\"># same type</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">TypeError</span>: field 0: Can not merge type &lt;class &#39;pyspark.sql.types.StringType&#39;&gt; and &lt;class &#39;pyspark.sql.types.DoubleType&#39;&gt;</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "name": "2020-09-12 - DBFS Example",
  "notebookId": 1820551709779350
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
